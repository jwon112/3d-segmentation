# 3D Segmentation Project

3D ë‡Œì¢…ì–‘ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
3d_segmentation/
â”œâ”€â”€ models/                             # ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ channel_configs.py             # ì¤‘ì•™ ì§‘ì¤‘ì‹ ì±„ë„ ì„¤ì • (_xs, _s, _m, _l)
â”‚   â”œâ”€â”€ model_3d_unet.py               # 3D U-Net (í¬ê¸°: xs, s, m, l)
â”‚   â”œâ”€â”€ model_3d_unet_stride.py        # 3D U-Net Stride (í¬ê¸°: xs, s, m, l)
â”‚   â”œâ”€â”€ model_3d_unet_modal_comparison.py  # ëª¨ë‹¬ë¦¬í‹° ë¹„êµ ëª¨ë¸ (2modal, 4modal, quadbranch)
â”‚   â”œâ”€â”€ model_unetr.py                 # UNETR ëª¨ë¸
â”‚   â”œâ”€â”€ model_swin_unetr.py            # Swin UNETR ëª¨ë¸
â”‚   â”œâ”€â”€ mobileunetr.py                 # Mobile UNETR (2D)
â”‚   â”œâ”€â”€ mobileunetr_3d.py              # Mobile UNETR 3D
â”‚   â”œâ”€â”€ dualbranch_basic.py            # Dual-Branch ê¸°ë³¸ (MaxPool, Stride, Dilated)
â”‚   â”œâ”€â”€ dualbranch_replk.py            # Dual-Branch RepLK (RepLK + MViT)
â”‚   â”œâ”€â”€ dualbranch_mobile.py           # Dual-Branch MobileNetV2 (Shuffle-inspired)
â”‚   â”œâ”€â”€ dualbranch_mvit.py             # Dual-Branch MobileViT Extended
â”‚   â”œâ”€â”€ dualbranch_14_unet.py          # Dual-Branch Backbone ë¹„êµ (MobileNetV2, GhostNet, ShuffleNetV2, ConvNeXt ë“±)
â”‚   â””â”€â”€ modules/                       # ê³µí†µ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ replk_modules.py           # RepLK ê´€ë ¨ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ mvit_modules.py            # MobileViT ê´€ë ¨ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ ghostnet_modules.py        # GhostNet ê´€ë ¨ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ shufflenet_modules.py      # ShuffleNetV2 ê´€ë ¨ ëª¨ë“ˆ
â”‚       â””â”€â”€ convnext_modules.py        # ConvNeXt ê´€ë ¨ ëª¨ë“ˆ
â”œâ”€â”€ utils/                              # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiment_utils.py            # ì‹¤í—˜ ìœ í‹¸ë¦¬í‹° (ëª¨ë¸ ìƒì„±, PAM ê³„ì‚°, ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë“±)
â”‚   â”œâ”€â”€ gradcam_utils.py               # Grad-CAM ìœ í‹¸ë¦¬í‹° (í˜„ì¬ ë¹„í™œì„±í™”)
â”‚   â”œâ”€â”€ debug_*.py                     # ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â””â”€â”€ *.md                           # ë¬¸ì„œí™” íŒŒì¼ë“¤
â”œâ”€â”€ losses/                             # Loss í•¨ìˆ˜
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ losses.py                      # Combined Loss, nnU-Net Style Loss
â”œâ”€â”€ metrics/                            # í‰ê°€ ë©”íŠ¸ë¦­
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ metrics.py                     # Dice Score, WT/TC/ET ê³„ì‚°
â”œâ”€â”€ visualization/                      # ì‹œê°í™” ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ visualization_3d.py            # 3D ì‹œê°í™” (ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›)
â”‚   â”œâ”€â”€ visualization_dataframe.py     # DataFrame ê¸°ë°˜ ì‹œê°í™” ë° ì°¨íŠ¸ ìƒì„±
â”‚   â””â”€â”€ gradcam_3d.py                  # Grad-CAM 3D ì‹œê°í™” (í˜„ì¬ ë¹„í™œì„±í™”)
â”œâ”€â”€ baseline_results/                   # ì‹¤í—˜ ê²°ê³¼ ì €ì¥
â”œâ”€â”€ data/                               # ë°ì´í„°ì…‹
â”œâ”€â”€ integrated_experiment.py            # í†µí•© ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (CLI ì§„ì…ì )
â”œâ”€â”€ experiment_runner.py                # ì‹¤í—˜ ì‹¤í–‰ ë¡œì§ (train_model, evaluate_model, run_integrated_experiment)
â”œâ”€â”€ evaluate_experiment.py              # ì²´í¬í¬ì¸íŠ¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data_loader.py                      # ë°ì´í„° ë¡œë” (BraTS ë°ì´í„°ì…‹)
â””â”€â”€ requirements.txt                    # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
conda create -n 3d_segmentation python=3.9
conda activate 3d_segmentation

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ë°ì´í„° ì¤€ë¹„

#### ë°ì´í„°ì…‹ êµ¬ì¡°

**BRATS2018**:
```
{data_path}/
â””â”€â”€ BRATS2018/
    â””â”€â”€ MICCAI_BraTS_2018_Data_Training/
        â”œâ”€â”€ HGG/          # High-Grade Glioma (~210 samples)
        â””â”€â”€ LGG/          # Low-Grade Glioma (~75 samples)
```

**BRATS2021**:
```
{data_path}/
â””â”€â”€ BRATS2021/
    â””â”€â”€ BraTS2021_Training_Data/  # ~1,251 samples
        â”œâ”€â”€ BraTS2021_00000/
        â”œâ”€â”€ BraTS2021_00001/
        â””â”€â”€ ...
```

#### ê²½ë¡œ ì„¤ì •

- **ì„œë²„**: `/home/work/3D_/BT/` (ê¸°ë³¸ê°’)
- **ë¡œì»¬**: `C:\Users\user\Desktop\ì„±ê· ê´€ëŒ€\3d_segmentation\data` (Windows) ë˜ëŠ” `/path/to/data` (Linux/Mac)

ë°ì´í„°ì…‹ì€ ê³µí†µ ê²½ë¡œ(`--data_path`) ì•„ë˜ì— `BRATS2018/` ë˜ëŠ” `BRATS2021/` í´ë”ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

### 3. ì‹¤í—˜ ì‹¤í–‰

#### ê¸°ë³¸ ì‹¤í—˜ (ë‹¨ì¼ ì‹œë“œ)
```bash
python integrated_experiment.py --epochs 10 --batch_size 1 --seeds 24
```

#### ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜
```bash
python integrated_experiment.py --epochs 10 --batch_size 1 --seeds 24 42 123
```

#### íŠ¹ì • ëª¨ë¸ë§Œ ì‹¤í—˜
```bash
python integrated_experiment.py --epochs 10 --models unet3d_s dualbranch_01_unet_s
```

#### BRATS2018 ë°ì´í„°ì…‹ ì‚¬ìš©
```bash
python integrated_experiment.py --dataset_version brats2018 --epochs 10
```

#### BRATS2021 ë°ì´í„°ì…‹ ì‚¬ìš©
```bash
python integrated_experiment.py --dataset_version brats2021 --epochs 10
```

#### 3D ëª¨ë¸ í•™ìŠµ (3D ë°ì´í„° ì‚¬ìš©)
```bash
python integrated_experiment.py --dim 3d --epochs 10 --batch_size 1
```

#### 5-Fold Cross-Validation
```bash
python integrated_experiment.py --use_5fold --epochs 10 --seeds 24
```

#### ë¶„ì‚° í•™ìŠµ (Multi-GPU)
```bash
# 2ê°œ GPU ì‚¬ìš©
torchrun --nproc_per_node=2 integrated_experiment.py --epochs 10 --batch_size 2

# 4ê°œ GPU ì‚¬ìš©
torchrun --nproc_per_node=4 integrated_experiment.py --epochs 10 --batch_size 4

# íŠ¹ì • GPUë§Œ ì‚¬ìš© (ì˜ˆ: GPU 0, 1ë§Œ ì‚¬ìš©)
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 integrated_experiment.py --epochs 10

# ë©€í‹° ë…¸ë“œ (ì˜ˆ: 2ë…¸ë“œ, ê°ê° 4 GPU)
torchrun --nnodes=2 --node_rank=0 --nproc_per_node=4 --master_addr=<MASTER_IP> --master_port=29500 integrated_experiment.py --epochs 10
```

## ğŸ“ ì‹¤í–‰ ì˜µì…˜

### ì£¼ìš” ì˜µì…˜

| ì˜µì…˜ | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|------|--------|------|
| `--data_path` | str | `/home/work/3D_/BT/` | ë°ì´í„°ì…‹ ê³µí†µ ê²½ë¡œ (ì„œë²„/ë¡œì»¬ ê²½ë¡œ ì§€ì •) |
| `--dataset_version` | str | `brats2018` | ë°ì´í„°ì…‹ ë²„ì „: `brats2018` ë˜ëŠ” `brats2021` |
| `--epochs` | int | `10` | í›ˆë ¨ ì—í¬í¬ ìˆ˜ |
| `--batch_size` | int | `1` | ë°°ì¹˜ í¬ê¸° (ë¶„ì‚° í•™ìŠµ ì‹œ GPUë‹¹ ë°°ì¹˜ í¬ê¸°) |
| `--seeds` | list[int] | `[24]` | ì‹¤í—˜ ì‹œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: `--seeds 24 42 123`) |
| `--models` | list[str] | `None` | ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  ëª¨ë¸) |
| `--dim` | str | `2d` | ë°ì´í„° ì°¨ì›: `2d` ë˜ëŠ” `3d` |
| `--use_pretrained` | flag | `False` | Pretrained ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€ |
| `--use_nnunet_loss` | flag | `True` | nnU-Net ìŠ¤íƒ€ì¼ loss ì‚¬ìš© (Dice 70% + CE 30%) |
| `--use_standard_loss` | flag | `False` | í‘œì¤€ loss ì‚¬ìš© (Dice 50% + CE 50%) |
| `--num_workers` | int | `8` | DataLoader ì›Œì»¤ ìˆ˜ |
| `--sharing_strategy` | str | `file_descriptor` | PyTorch tensor sharing ì „ëµ: `file_descriptor` ë˜ëŠ” `file_system` |
| `--use_5fold` | flag | `False` | 5-fold cross-validation ì‚¬ìš© |

### ëª¨ë¸ ì„ íƒ ì˜µì…˜

#### ê¸°ë³¸ U-Net ëª¨ë¸ (í¬ê¸°: xs, s, m, l)
- `unet3d_xs`: 3D U-Net Extra Small
- `unet3d_s`: 3D U-Net Small
- `unet3d_m`: 3D U-Net Medium
- `unet3d_l`: 3D U-Net Large
- `unet3d_stride_xs`: 3D U-Net Stride Extra Small (Stride Conv downsampling)
- `unet3d_stride_s`: 3D U-Net Stride Small
- `unet3d_stride_m`: 3D U-Net Stride Medium
- `unet3d_stride_l`: 3D U-Net Stride Large

**í¬ê¸°ë³„ ì±„ë„ ì¦ê°€**: ê° í¬ê¸°ê°€ 2ë°°ì”© ì¦ê°€ (xs â†’ s â†’ m â†’ l)

#### Transformer ê¸°ë°˜ ëª¨ë¸
- `unetr`: UNETR
- `swin_unetr`: Swin UNETR
- `mobile_unetr`: Mobile UNETR (2D ì „ìš©)
- `mobile_unetr_3d`: Mobile UNETR 3D

#### Dual-Branch ëª¨ë¸ (T1ce, FLAIR ì´ì¤‘ ë¶„ê¸°, í¬ê¸°: xs, s, m, l)
- `dualbranch_01_unet_{xs|s|m|l}`: ê¸°ë³¸ Dual-Branch (MaxPool)
- `dualbranch_02_unet_{xs|s|m|l}`: Stride Conv ë²„ì „
- `dualbranch_03_unet_{xs|s|m|l}`: Dilated Conv (FLAIRë§Œ)
- `dualbranch_04_unet_{xs|s|m|l}`: RepLK 13x13x13 (FLAIRë§Œ)
- `dualbranch_05_unet_{xs|s|m|l}`: RepLK + FFN2
- `dualbranch_06_unet_{xs|s|m|l}`: RepLK + MViT Stage 4,5
- `dualbranch_07_unet_{xs|s|m|l}`: RepLK + MViT Stage 5ë§Œ
- `dualbranch_mobilenetv2_dilated_{xs|s|m|l}`: MobileNetV2 ë“€ì–¼ ë¶„ê¸° (Shuffle-inspired, Stage3 Fused)
- `dualbranch_mobilenetv2_dilated_fixed_{xs|s|m|l}`: MobileNetV2 ë“€ì–¼ ë¶„ê¸° (Fixed Decoder ë³€í˜•)
- `dualbranch_13_unet_{xs|s|m|l}`: MobileViT Extended
- `dualbranch_14_mobilenetv2_expand2_{xs|s|m|l}`: MobileNetV2 (expand_ratio=2)
- `dualbranch_14_ghostnet_{xs|s|m|l}`: GhostNet
- `dualbranch_14_dilated_{xs|s|m|l}`: Dilated Conv (rate 1,2,5)
- `dualbranch_14_convnext_{xs|s|m|l}`: ConvNeXt
- `dualbranch_14_shufflenetv2_{xs|s|m|l}`: ShuffleNetV2
- `dualbranch_14_shufflenetv2_dilated_{xs|s|m|l}`: ShuffleNetV2 Dilated
- `dualbranch_14_shufflenetv2_lk_{xs|s|m|l}`: ShuffleNetV2 Large Kernel

**ì˜ˆì‹œ**: `dualbranch_01_unet_s`, `dualbranch_01_unet_m`, `dualbranch_14_ghostnet_l` ë“±

#### ëª¨ë‹¬ë¦¬í‹° ë¹„êµ ëª¨ë¸
- `unet3d_2modal_s`: ë‹¨ì¼ ë¶„ê¸°, 2ì±„ë„ (T1ce, FLAIR) concat
- `unet3d_4modal_s`: ë‹¨ì¼ ë¶„ê¸°, 4ì±„ë„ (T1, T1ce, T2, FLAIR) concat
- `dualbranch_2modal_unet_s`: 2ê°œ ë¶„ê¸° (T1ce, FLAIR)
- `quadbranch_4modal_unet_s`: 4ê°œ ë¶„ê¸° (T1, T1ce, T2, FLAIR) - ì–´í…ì…˜ ì—†ìŒ
- `quadbranch_4modal_attention_unet_s`: 4ê°œ ë¶„ê¸° + ì±„ë„ ì–´í…ì…˜

### ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •

#### ì„œë²„ í™˜ê²½
```bash
# ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (ì„œë²„)
python integrated_experiment.py --epochs 10

# ë˜ëŠ” ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
python integrated_experiment.py --data_path /home/work/3D_/BT/ --epochs 10
```

#### ë¡œì»¬ í™˜ê²½
```bash
# Windows
python integrated_experiment.py --data_path "C:\Users\user\Desktop\ì„±ê· ê´€ëŒ€\3d_segmentation\data" --epochs 10

# Linux/Mac
python integrated_experiment.py --data_path /path/to/data --epochs 10
```

## ğŸ”„ ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### ì „ì²˜ë¦¬

1. **NIfTI íŒŒì¼ ë¡œë“œ**: BraTS ë°ì´í„°ì…‹ì—ì„œ ëª¨ë‹¬ë¦¬í‹°ë³„ íŒŒì¼ ìë™ ê°ì§€
2. **ì •ê·œí™”**: 
   - ë¹„ì˜ì  ì˜ì—­ë§Œ ì¶”ì¶œ (vol > 0)
   - í¼ì„¼íƒ€ì¼ í´ë¦¬í•‘: [0.5%, 99.5%]
   - Z-score ì •ê·œí™”: (clipped - mean) / std
   - ë°°ê²½ ì˜ì—­ì€ 0ìœ¼ë¡œ ìœ ì§€
3. **ë¼ë²¨ ë§¤í•‘**: BraTS ì›ë³¸ ë¼ë²¨ 4 â†’ ëª¨ë¸ ë¼ë²¨ 3 (ET)
4. **ë°ì´í„° ë¶„í• **: 
   - ì¼ë°˜: train 80% / val 10% / test 10%
   - 5-Fold CV: 5ê°œ foldë¡œ ë¶„í•  (ê° fold 20%)
5. **íŒ¨ì¹˜ ìƒ˜í”Œë§** (3D í•™ìŠµ ì‹œ):
   - 33.3%: í¬ê·¸ë¼ìš´ë“œ ì˜¤ë²„ìƒ˜í”Œë§ (í´ë˜ìŠ¤ 1,2,3 ì¤‘ì‹¬)
   - 66.7%: ì™„ì „ ë¬´ì‘ìœ„ ìƒ˜í”Œë§

### í›„ì²˜ë¦¬

1. **ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì¶”ë¡ ** (3D í‰ê°€ ì‹œ):
   - íŒ¨ì¹˜ í¬ê¸°: (128, 128, 128)
   - Overlap: 0.10 (ê²€ì¦/í…ŒìŠ¤íŠ¸)
   - Cosine blendingìœ¼ë¡œ íŒ¨ì¹˜ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ìœµí•©
2. **ì˜ˆì¸¡ ìƒì„±**: Logits â†’ Softmax â†’ Argmax
3. **ë©”íŠ¸ë¦­ ê³„ì‚°**:
   - Dice Score (WT/TC/ET)
   - Precision/Recall (í´ë˜ìŠ¤ë³„)
   - Confusion Matrix

## ğŸ§  ì§€ì› ëª¨ë¸

### 1. 3D U-Net
- **ê¸°ë³¸ ë²„ì „**: MaxPool ê¸°ë°˜ downsampling
- **Stride ë²„ì „**: Stride-2 Conv ê¸°ë°˜ downsampling
- **í¬ê¸°**: Extra Small, Small, Medium, Large (ê° í¬ê¸°ë§ˆë‹¤ ì±„ë„ì´ 2ë°°ì”© ì¦ê°€)
  - **xs**: ìµœì†Œ ì±„ë„ ìˆ˜
  - **s**: Small (ê¸°ë³¸)
  - **m**: Medium (Smallì˜ 2ë°°)
  - **l**: Large (Mediumì˜ 2ë°°)

### 2. UNETR
- **íŠ¹ì§•**: Vision Transformer ê¸°ë°˜ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜
- **ì¥ì **: ê¸´ ê±°ë¦¬ ì˜ì¡´ì„± í•™ìŠµ ê°€ëŠ¥
- **ë‹¨ì **: ë†’ì€ ê³„ì‚° ë¹„ìš©

### 3. Swin UNETR
- **íŠ¹ì§•**: Swin Transformer ê¸°ë°˜ ê³„ì¸µì  êµ¬ì¡°
- **ì¥ì **: íš¨ìœ¨ì ì¸ ê³„ì‚°ê³¼ ì¢‹ì€ ì„±ëŠ¥

### 4. Mobile UNETR
- **2D ë²„ì „**: Mobile UNETR (2D ì „ìš©)
- **3D ë²„ì „**: Mobile UNETR 3D

### 5. Dual-Branch U-Net
- **êµ¬ì¡°**: T1ceì™€ FLAIRë¥¼ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ í›„ ìœµí•©
- **Stage 1-4**: Dual-branch êµ¬ì¡° ìœ ì§€
- **Stage 5+**: ìœµí•©ëœ branch (MobileViT ë˜ëŠ” í‘œì¤€ UNet)
- **ë³€í˜•**: ë‹¤ì–‘í•œ backbone (RepLK, MobileNetV2, Dilated Conv, MobileViT, GhostNet, ShuffleNetV2, ConvNeXt ë“±)
- **í¬ê¸°**: ëª¨ë“  ëª¨ë¸ì´ xs, s, m, l í¬ê¸° ì§€ì› (ì±„ë„ ìˆ˜ 2ë°°ì”© ì¦ê°€)

### 6. Quad-Branch U-Net
- **êµ¬ì¡°**: T1, T1ce, T2, FLAIRë¥¼ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ í›„ ìœµí•©
- **ì–´í…ì…˜ ë²„ì „**: ì±„ë„ ì–´í…ì…˜ìœ¼ë¡œ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ì¸¡ì • ê°€ëŠ¥

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

ì‹¤í—˜ ê²°ê³¼ëŠ” `baseline_results/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤:

- `integrated_experiment_results_YYYYMMDD_HHMMSS/`
  - `integrated_experiment_results.csv`: ëª¨ë¸ë³„ ì„±ëŠ¥ ìš”ì•½ (PAM, Inference Latency í¬í•¨)
  - `all_epochs_results.csv`: ì—í¬í¬ë³„ ìƒì„¸ ê²°ê³¼
  - `model_comparison.csv`: ëª¨ë¸ ë¹„êµ ë¶„ì„ (í‰ê· /í‘œì¤€í¸ì°¨, PAM, Inference Latency í¬í•¨)
  - `stage_wise_pam_results.csv`: Stageë³„ PAM ë¶„ì„ ê²°ê³¼
  - `learning_curves.png`: í•™ìŠµ ê³¡ì„  ì°¨íŠ¸
  - `model_comparison_chart.png`: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ (PAM Train/Inference í¬í•¨)
  - `parameter_efficiency.png`: íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¶„ì„
  - `interactive_3d_analysis.html`: ì¸í„°ë™í‹°ë¸Œ 3D ë¶„ì„
  - `{model_name}_seed_{seed}_best.pth`: ê° ëª¨ë¸ë³„ ìµœì  ì²´í¬í¬ì¸íŠ¸
  - `{model_name}_seed_{seed}_fold_{fold}_best.pth`: 5-fold CV ì‹œ foldë³„ ì²´í¬í¬ì¸íŠ¸
  - `gradcam/`: Grad-CAM ì‹œê°í™” ê²°ê³¼ (í˜„ì¬ ë¹„í™œì„±í™”)

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### 1. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ
- ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ ë™ì‹œ í›ˆë ¨ ë° ë¹„êµ
- ëª¨ë¸ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ (Dice Score, Precision, Recall)
- íŒŒë¼ë¯¸í„° ìˆ˜, FLOPs, PAM íš¨ìœ¨ì„± ë¶„ì„

### 2. ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
- í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ì„ ìœ„í•œ ë‹¤ì¤‘ ì‹œë“œ í‰ê· 
- ì‹œë“œë³„ ì„±ëŠ¥ ë¶„í¬ ë¶„ì„

### 3. 5-Fold Cross-Validation
- ì‹ ë¢°ì„± í–¥ìƒì„ ìœ„í•œ 5-fold CV ì§€ì›
- ê° foldë³„ ê²°ê³¼ ì €ì¥ ë° í‰ê·  ê³„ì‚°

### 4. PAM (Peak Activation Memory) ì¸¡ì •
- Train/Inference ë‹¨ê³„ë³„ VRAM ì‚¬ìš©ëŸ‰ ì¸¡ì •
- 5íšŒ ì¸¡ì • í›„ í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
- ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ
- **Stage-wise PAM**: ëª¨ë¸ì˜ ê° stageë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ (ë³„ë„ CSV ì €ì¥)

### 5. ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¶„ì„
- Quad-Branch ëª¨ë¸ì—ì„œ ì±„ë„ ì–´í…ì…˜ìœ¼ë¡œ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ì¸¡ì •
- ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì‹œê°í™” ë° ì €ì¥

### 6. 3D ì‹œê°í™”
- ìŠ¬ë¼ì´ìŠ¤ë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” (ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›)
- í•™ìŠµ ê³¡ì„  ë° ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
- ì¸í„°ë™í‹°ë¸Œ 3D ë¶„ì„ í”Œë¡¯
- DataFrame ê¸°ë°˜ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„

### 7. ìë™í™”ëœ ì‹¤í—˜ ê´€ë¦¬
- ì²´í¬í¬ì¸íŠ¸ ìë™ ì €ì¥
- ì‹¤í—˜ ê²°ê³¼ ìë™ ì •ë¦¬
- ì‹œê°í™” ì°¨íŠ¸ ìë™ ìƒì„±

## ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­

### 1. Dice Score
- ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •í™•ë„ ì¸¡ì •
- BraTS í‘œì¤€ í‰ê°€ ì§€í‘œ:
  - **WT (Whole Tumor)**: í´ë˜ìŠ¤ 1 âˆª 2 âˆª 3
  - **TC (Tumor Core)**: í´ë˜ìŠ¤ 1 âˆª 3
  - **ET (Enhancing Tumor)**: í´ë˜ìŠ¤ 3
- í´ë˜ìŠ¤ë³„ Dice Score ê³„ì‚°
- í‰ê·  Dice Scoreë¡œ ì „ì²´ ì„±ëŠ¥ í‰ê°€

### 2. Precision & Recall
- í´ë˜ìŠ¤ë³„ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨
- Background í´ë˜ìŠ¤ ì œì™¸í•œ í‰ê· 
- ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ ìƒì„¸ ë¶„ì„

### 3. ëª¨ë¸ íš¨ìœ¨ì„±
- **íŒŒë¼ë¯¸í„° ìˆ˜** (Parameters)
- **ì—°ì‚°ëŸ‰** (FLOPs)
- **PAM** (Peak Activation Memory): Train/Inference ë‹¨ê³„ë³„ VRAM ì‚¬ìš©ëŸ‰
- **Inference Latency**: ì¶”ë¡  ì‹œê°„ (ms, batch_size=1 ê¸°ì¤€)

## ğŸš€ ë¶„ì‚° í•™ìŠµ ì„¤ì •

### 1. ë‹¨ì¼ ë…¸ë“œ ë©€í‹° GPU (Single Node Multi-GPU)

#### Linux/ì„œë²„ í™˜ê²½ (torchrun ì‚¬ìš© - ê¶Œì¥)
```bash
# 4ê°œ GPU ì‚¬ìš©
torchrun --nproc_per_node=4 integrated_experiment.py \
    --epochs 10 \
    --batch_size 4 \
    --seeds 24

# íŠ¹ì • GPUë§Œ ì‚¬ìš© (ì˜ˆ: GPU 2, 3ë§Œ ì‚¬ìš©)
CUDA_VISIBLE_DEVICES=2,3 torchrun --nproc_per_node=2 integrated_experiment.py \
    --epochs 10 \
    --batch_size 2
```

#### Windows í™˜ê²½ (libuv ì˜¤ë¥˜ í•´ê²°)
Windowsì—ì„œëŠ” PyTorchê°€ libuv ì§€ì› ì—†ì´ ë¹Œë“œëœ ê²½ìš° ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# ë°©ë²• 1: í™˜ê²½ ë³€ìˆ˜ë¡œ libuv ë¹„í™œì„±í™”
set USE_LIBUV=0
torchrun --nproc_per_node=4 integrated_experiment.py --epochs 10 --batch_size 4

# ë°©ë²• 2: PowerShellì—ì„œ
$env:USE_LIBUV=0
torchrun --nproc_per_node=4 integrated_experiment.py --epochs 10 --batch_size 4

# ë°©ë²• 3: í•œ ì¤„ë¡œ ì‹¤í–‰
$env:USE_LIBUV=0; torchrun --nproc_per_node=4 integrated_experiment.py --epochs 10 --batch_size 4
```

**ì°¸ê³ **: Windowsì—ì„œëŠ” `torchrun`ì´ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Linux/ì„œë²„ í™˜ê²½ì—ì„œ ë¶„ì‚° í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### 2. ë©€í‹° ë…¸ë“œ (Multi-Node)

#### ë…¸ë“œ 0 (Master)
```bash
torchrun \
    --nnodes=2 \
    --node_rank=0 \
    --nproc_per_node=4 \
    --master_addr=<MASTER_IP> \
    --master_port=29500 \
    integrated_experiment.py --epochs 10 --batch_size 4
```

#### ë…¸ë“œ 1 (Worker)
```bash
torchrun \
    --nnodes=2 \
    --node_rank=1 \
    --nproc_per_node=4 \
    --master_addr=<MASTER_IP> \
    --master_port=29500 \
    integrated_experiment.py --epochs 10 --batch_size 4
```

### 3. ë¶„ì‚° í•™ìŠµ ì£¼ì˜ì‚¬í•­

#### ë°°ì¹˜ í¬ê¸° ì„¤ì •
- **ë¶„ì‚° í•™ìŠµ ì‹œ**: `--batch_size`ëŠ” GPUë‹¹ ë°°ì¹˜ í¬ê¸°ì…ë‹ˆë‹¤
- **ì „ì²´ ë°°ì¹˜ í¬ê¸°**: `batch_size Ã— num_gpus`
- ì˜ˆ: `--batch_size 2` + 4 GPU = ì „ì²´ ë°°ì¹˜ í¬ê¸° 8

#### ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# /dev/shm ê³µê°„ ë¶€ì¡± ì‹œ file_system ì „ëµ ì‚¬ìš©
python integrated_experiment.py \
    --sharing_strategy file_system \
    --num_workers 4 \
    --epochs 10
```

#### DataLoader ì›Œì»¤ ìˆ˜
- ë¶„ì‚° í•™ìŠµ ì‹œ ê° GPU í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ ì›Œì»¤ê°€ ìƒì„±ë©ë‹ˆë‹¤
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ `--num_workers`ë¥¼ ì¤„ì´ì„¸ìš” (ê¸°ë³¸ê°’: 8)

### 4. ë¶„ì‚° í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë“  ë…¸ë“œì—ì„œ ë™ì¼í•œ ì½”ë“œì™€ ë°ì´í„° ê²½ë¡œ ì‚¬ìš©
- [ ] ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ (NCCL ë°±ì—”ë“œ ì‚¬ìš©)
- [ ] ë°©í™”ë²½ ì„¤ì • í™•ì¸ (master_port ê°œë°©)
- [ ] ê° ë…¸ë“œì˜ GPUê°€ ë™ì¼í•œ CUDA ë²„ì „ ì‚¬ìš©
- [ ] ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ê°€ëŠ¥ (ë°ì´í„°ì…‹ ê³µìœ )
- [ ] **Windows í™˜ê²½**: `USE_LIBUV=0` í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í™•ì¸

### 5. Windows í™˜ê²½ ì£¼ì˜ì‚¬í•­

Windowsì—ì„œ ë¶„ì‚° í•™ìŠµ ì‹œ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
torch.distributed.DistStoreError: use_libuv was requested but PyTorch was built without libuv support
```

**í•´ê²° ë°©ë²•**:
1. í™˜ê²½ ë³€ìˆ˜ `USE_LIBUV=0` ì„¤ì • (ìœ„ ì°¸ì¡°)
2. ë˜ëŠ” Linux/ì„œë²„ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê¶Œì¥

**Windows ì œí•œì‚¬í•­**:
- `torchrun`ì˜ ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŒ
- ë©€í‹° ë…¸ë“œ ë¶„ì‚° í•™ìŠµì€ Linux í™˜ê²½ì—ì„œë§Œ ì§€ì›
- ë‹¨ì¼ ë…¸ë“œ ë©€í‹° GPUëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ, Linux í™˜ê²½ì„ ê¶Œì¥

## ğŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€
1. `models/` í´ë”ì— ìƒˆ ëª¨ë¸ íŒŒì¼ ìƒì„±
2. `models/__init__.py`ì— ëª¨ë¸ import ì¶”ê°€
3. `utils/experiment_utils.py`ì˜ `get_model()` í•¨ìˆ˜ì— ëª¨ë¸ ì¼€ì´ìŠ¤ ì¶”ê°€
4. í¬ê¸°ë³„ ì±„ë„ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš° `models/channel_configs.py`ì— ì¶”ê°€
5. ê³µí†µ ëª¨ë“ˆì€ `models/modules/` í´ë”ì— ì¶”ê°€

### ì‹¤í—˜ ì„¤ì • ë³€ê²½
- `integrated_experiment.py`ì˜ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ìˆ˜ì •
- ëª…ë ¹í–‰ ì¸ìë¡œ ì‹¤ì‹œê°„ ì„¤ì • ë³€ê²½ ê°€ëŠ¥

### ì‹œê°í™” ì»¤ìŠ¤í„°ë§ˆì´ì§•
- `visualization/visualization_3d.py`: ë‹¤ì¤‘ ëª¨ë¸ 3D ì‹œê°í™”
- `visualization/visualization_dataframe.py`: DataFrame ê¸°ë°˜ ë¶„ì„ ì°¨íŠ¸
- ìƒˆë¡œìš´ ë¶„ì„ ì°¨íŠ¸ ì¶”ê°€ ê°€ëŠ¥

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´
- GPU: CUDA ì§€ì› GPU (ê¶Œì¥: RTX 3080 ì´ìƒ)
- RAM: 16GB ì´ìƒ
- ì €ì¥ê³µê°„: 50GB ì´ìƒ

### ì†Œí”„íŠ¸ì›¨ì–´
- Python 3.9+
- PyTorch 1.12+
- CUDA 11.0+

### ì£¼ìš” íŒ¨í‚¤ì§€
- torch, torchvision
- numpy, pandas
- matplotlib, seaborn
- plotly
- tqdm
- thop (FLOPs ê³„ì‚°ìš©)
- nibabel (NIfTI íŒŒì¼ ì²˜ë¦¬)

## ğŸ› ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
- `batch_size`ë¥¼ 1ë¡œ ì„¤ì •
- `max_samples` íŒŒë¼ë¯¸í„°ë¡œ ë°ì´í„° í¬ê¸° ì œí•œ
- ëª¨ë¸ í¬ê¸° ì¶•ì†Œ (Small ë²„ì „ ì‚¬ìš©)
- ìŠ¬ë¼ì´ë”© ìœˆë„ìš° overlap ì¤„ì´ê¸°

### CUDA ì˜¤ë¥˜
- CUDA ë²„ì „ê³¼ PyTorch ë²„ì „ í˜¸í™˜ì„± í™•ì¸
- `torch.cuda.is_available()` í™•ì¸

### ë°ì´í„° ë¡œë”© ì˜¤ë¥˜
- ë°ì´í„° ê²½ë¡œ í™•ì¸
- NIfTI íŒŒì¼ í˜•ì‹ í™•ì¸
- íŒŒì¼ëª… íŒ¨í„´ í™•ì¸ (t1ce, flair, seg)

### NCCL Timeout ì˜¤ë¥˜
- NCCL timeout ì¦ê°€: `export NCCL_TIMEOUT=1800`
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
- GPU ê°„ í†µì‹  ì†ë„ í™•ì¸

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. **3D U-Net**: Ã‡iÃ§ek, Ã–., et al. "3D U-Net: learning dense volumetric segmentation from sparse annotation."
2. **UNETR**: Hatamizadeh, A., et al. "UNETR: Transformers for 3D Medical Image Segmentation."
3. **Swin UNETR**: Hatamizadeh, A., et al. "Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images."
4. **nnU-Net**: Isensee, F., et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation."

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**Note**: ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ì˜ë£Œ ì§„ë‹¨ì— ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
